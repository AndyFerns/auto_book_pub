# ğŸ“˜ Automated Book Publication Workflow

An intelligent agent-driven pipeline to automate the rewriting and publication of public-domain books with human-in-the-loop editing and content versioning.

---

## âœ¨ Features

- **ğŸŒ Web Scraping**  
  Scrapes book chapters from online sources (e.g., [Wikisource](https://en.wikisource.org)) using Playwright.

- **ğŸ§  AI Content Generation**  
  Uses a multi-agent architecture (Writer & Reviewer) powered by LLMs (like Google Gemini) to rewrite and refine chapters.

- **ğŸ§‘â€ğŸ’» Human-in-the-Loop Editing**  
  Optional manual feedback after AI rewriting allows human writers/editors to make changes before finalizing.

- **ğŸ“š Content Versioning**  
  Final outputs are saved into **ChromaDB** with automatic version labels (v1, v2, ...), UUIDs, and metadata.

- **ğŸ” RL-inspired Retrieval**  
  Query past versions using TF-IDF + cosine similarity (stubbed for future reinforcement learning-based retrieval).

---

## ğŸ“‚ Directory Structure

```text
auto_book_pub/
â”œâ”€â”€ main.py                    # Entry point
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.yaml
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   # Raw scraped HTML + screenshots
â”‚   â”œâ”€â”€ processed/             # AI-edited versions
â”‚   â””â”€â”€ versions/              # Finalized, versioned outputs
â”œâ”€â”€ scraping/
â”‚   â””â”€â”€ scraper.py             # Playwright-based scraper
â”œâ”€â”€ ai_agents/
â”‚   â”œâ”€â”€ writer_agent.py        # AI "spinner"
â”‚   â”œâ”€â”€ reviewer_agent.py      # Reviewer LLM
â”‚   â””â”€â”€ editor_agent.py        # Optional human/AI edit flow
â”œâ”€â”€ human_loop/
â”‚   â””â”€â”€ feedback_manager.py    # Handle user input iterations
â”œâ”€â”€ versioning/
â”‚   â””â”€â”€ chromadb_manager.py    # Store/retrieve versioned content
â”œâ”€â”€ rl_search/
â”‚   â””â”€â”€ retriever.py           # Reinforcement Learning-based retriever
â””â”€â”€ utils/
    â””â”€â”€ helpers.py             # Common utilities

```

## ğŸš€ How It Works

1. **Scrape Content**

```python
   raw_text = scrape_chapter(target_url)
   ```

2. **AI Rewriting + Review**

```python
rewritten = WriterAgent().spin(raw_text)
reviewed  = ReviewerAgent().review(rewritten)

```

3. **Human Feedback (Optional)**

```python
final_version = collect_feedback(reviewed)
```

4. **Save to ChromaDB**

```python
save_version(final_version)
```

5. **Retrieve Similar Versions**

```python
results = retrieve_version("version-number")
```

## âš™ï¸ Setup

### ğŸ”§ Prerequisites

-Python 3.10+

-Google Gemini API Key (optional)

-Playwright dependencies

## ğŸ“¦ Installation

```bash
git clone https://github.com/yourusername/auto_book_pub
cd auto_book_pub
```

### Set up Python environment

```bash
pip install -r requirements.txt
```

### Set up Playwright

```bash
playwright install
```

### ğŸ” .env Configuration

Create a .env file:

```env
GEMINI_API_KEY=your_google_gemini_key
```

## ğŸ§ª Dev Mode (Optional)

To avoid re-scraping each time, enable dev mode in main.py:

```python
dev_mode = True
if dev_mode:
    raw_text = load_cached_text()
else:
    raw_text = scrape_chapter(url)
```

## ğŸ“„ License

MIT License. See LICENSE for details.
